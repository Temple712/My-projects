{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "baaaa622-27b9-4b07-9081-2d109867c089",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1. Set-up the configs using Azure key vaults and Databricks secrets scope\n",
    "### 2. Transform testing data\n",
    "#### Please update the following \n",
    "- client_id\n",
    "- tenant_id\n",
    "- client_secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62aea084-0464-4e79-8521-954e79790f7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "client_id = dbutils.secrets.get(scope=\"covid19-scope\", key=\"covid-19-client-id\")\n",
    "tenant_id = dbutils.secrets.get(scope=\"covid19-scope\", key=\"covid-19-tenant-id\")\n",
    "client_secret = dbutils.secrets.get(scope=\"covid19-scope\", key=\"covid-19-client-secrets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01f28a75-5806-4e6c-82ab-a1985bfd0a07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "configs = {\"fs.azure.account.auth.type\": \"OAuth\",\n",
    "           \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n",
    "           \"fs.azure.account.oauth2.client.id\": client_id,\n",
    "           \"fs.azure.account.oauth2.client.secret\": client_secret,\n",
    "           \"fs.azure.account.oauth2.client.endpoint\": f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\"}\n",
    "\n",
    "for key, value in configs.items(): spark.conf.set(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a8fe92c-097c-4d98-b09d-06fec0845ed5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17b3edcb-37d0-45e1-a6de-03e29bd16a5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_raw_testing = spark.read.option(\"header\", \"true\") \\\n",
    "               .csv(\"abfss://raw@covidreportdl712.dfs.core.windows.net/ecdc/testing.csv\")\n",
    "               \n",
    "df_raw_testing.createOrReplaceTempView(\"df_raw_testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c487bef5-d714-4b2f-9797-e79372679e01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a data frame for the country lookup\n",
    "df_dim_country = spark.read.csv(\"abfss://lookup@covidreportdl712.dfs.core.windows.net/country_lookup.csv\", sep=r',', header=True)\n",
    "df_dim_country.createOrReplaceTempView(\"dim_country\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e22aff67-1cb5-4de0-a3e8-a561c790cdfc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_testing_country_lookup = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    c.country,\n",
    "    c.country_code_2_digit,\n",
    "    c.country_code_3_digit,\n",
    "    t.year_week,\n",
    "    t.new_cases,\n",
    "    t.tests_done,\n",
    "    t.population,\n",
    "    cast(t.testing_rate AS FLOAT) as testing_rate ,\n",
    "    cast(t.positivity_rate AS FLOAT) as positivity_rate,\n",
    "    t.testing_data_source\n",
    "FROM df_raw_testing t\n",
    "JOIN dim_country c \n",
    "    ON t.country_code = c.country_code_2_digit\n",
    "ORDER BY c.country\n",
    "\"\"\")\n",
    "df_testing_country_lookup.createOrReplaceTempView(\"df_testing_country_lookup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fc652a3-285f-467e-8029-80781b0d60de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a data frame for the dim_date\n",
    "df_dim_date = spark.read.csv(\"abfss://lookup@covidreportdl712.dfs.core.windows.net/dim_date.csv\", sep=r',', header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e1c3625-b6eb-47b7-8575-ebb99e74020c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = (\n",
    "    df_dim_date\n",
    "    .withColumn(\n",
    "        \"year_week\",\n",
    "        concat(\n",
    "            col(\"year\"),\n",
    "            lit(\"-W\"),\n",
    "            lpad(col(\"week_of_year\").cast(\"string\"), 2, \"0\")\n",
    "        )\n",
    "    )\n",
    "    .select(\n",
    "        col(\"date\"),\n",
    "        col(\"year_week\")\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b21c2208-2df3-41db-a0f9-34d22fbaf461",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: Aggregate to get min and max date per week\n",
    "df_week_bounds = (\n",
    "    df.groupBy(\"year_week\")\n",
    "      .agg(\n",
    "          min(\"date\").alias(\"week_start_date\"),\n",
    "          max(\"date\").alias(\"week_end_date\")\n",
    "      )\n",
    ")\n",
    "\n",
    "df_week_bounds.createOrReplaceTempView(\"df_week_bounds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d9a0d0b-956e-4a76-b9d5-f82b9d844625",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_date_processsed = spark.sql(\"\"\"SELECT t.*,\n",
    "                                   w.week_start_date,\n",
    "                                   w.week_end_date\n",
    "  FROM df_testing_country_lookup t\n",
    "  JOIN df_week_bounds w ON t.year_week = w.year_week\n",
    " ORDER BY country\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6e70c69-e5ec-4ef8-8ba1-d68a8d76001b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_date_processsed.write.format(\"com.databricks.spark.csv\").option(\"header\",\"true\").option(\"delimiter\", \",\").mode(\"overwrite\").save(\"abfss://processed@covidreportdl712.dfs.core.windows.net/ecdc/testing\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "setup_and_transform_testing_data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}